# config/default.yaml
# Default configuration for semi-autonomous agent

general:
  workspace_path: "./Workspace"
  max_files_per_scan: 10
  debug_mode: false
  log_level: "INFO"

llm:
  default_provider: "lm_studio"
  # The following LLM variables will be loaded from .env (e.g., CONTEXT_WINDOW, TEMPERATURE)
  # context_window, temperature, and max_tokens are controlled via .env.
  providers:
    lm_studio:
      base_url: "http://localhost:1234/v1"
      timeout: 300
    anthropic:
      model: "claude-3-sonnet-20240229"
      timeout: 300
    openai:
      model: "gpt-4"
      timeout: 300

agent:
  auto_test: true
  max_retries: 3
  timeout: 300
  memory:
    short_term_limit: 100
    working_memory_limit: 50
    long_term_limit: 1000

storage:
  format: "json"
  compression: false
  backup_enabled: true
  max_backups: 5

validation:
  strict_mode: false
  auto_fix: true
  test_timeout: 30

monitoring:
  enabled: true
  metrics_interval: 60
  log_metrics: true
